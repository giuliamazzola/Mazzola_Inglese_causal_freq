[
  {
    "objectID": "causal_freq_full_code_dec25.html",
    "href": "causal_freq_full_code_dec25.html",
    "title": "Causalness, frequency, diachrony and the causal-noncausal alternation in Italian and Spanish",
    "section": "",
    "text": "Replication materials for: Mazzola & Inglese, “Causalness, frequency, diachrony and the causal-noncausal alternation in Italian and Spanish” in Corpus Linguistics and Linguistic Theory (Accepted December 2025). Full citation information will be released after publication.\n#| label: setup-packages\n#| echo: false\n#| message: false\n#| warning: false\n#| results: \"hide\"\n\npackages &lt;- c(\n  \"tidyverse\", \"knitr\", \"data.table\", \"DT\", \"here\", \"kableExtra\",\n  \"lme4\", \"openxlsx\", \"readxl\", \"wesanderson\", \"stringr\",\n  \"itsadug\", \"mgcv\", \"report\", \"gratia\", \"ggrepel\", \"gridExtra\"\n)\n\ninstalled_packages &lt;- rownames(installed.packages())\nto_install &lt;- setdiff(packages, installed_packages)\n\nif (length(to_install) &gt; 0) {\n  suppressMessages(install.packages(to_install))\n}\n\n\ninvisible(lapply(packages, function(pkg) {\n  suppressMessages(suppressWarnings(library(pkg, character.only = TRUE)))\n}))\n\n#Set working directory where this Rmd file lives\nsetwd(here::here())\n\n# Load data\n  romall&lt;-readxl::read_excel(\"romall_new_pub.xlsx\")\n  \n  nc&lt;-readxl::read_excel(\"noncaus_new_pub.xlsx\")"
  },
  {
    "objectID": "causal_freq_full_code_dec25.html#overall-purpose",
    "href": "causal_freq_full_code_dec25.html#overall-purpose",
    "title": "Causalness, frequency, diachrony and the causal-noncausal alternation in Italian and Spanish",
    "section": "Overall purpose",
    "text": "Overall purpose\nWe would like to include a new predictor in our dataset, namely the proportions of causal transitive uses (vs. non causal uses) of the verbs by time, which we define as causalness degree. In order to do so we need to come up with a periodisation for our data (spanning between 1140 and 2001), which allows to calculate the relative frequency of causal uses by time. To reach a periodisation, a visual survey of the data can be instructive, it might pose the problem of the analyst’s bias, as “different researchers may arrive at different groupings even for the same data set” (Gries & Hilpert 2008:2)."
  },
  {
    "objectID": "causal_freq_full_code_dec25.html#variability-neighbour-clustering-vnc",
    "href": "causal_freq_full_code_dec25.html#variability-neighbour-clustering-vnc",
    "title": "Causalness, frequency, diachrony and the causal-noncausal alternation in Italian and Spanish",
    "section": "Variability neighbour clustering (VNC)",
    "text": "Variability neighbour clustering (VNC)\nGries & Hilpert (2008) propose a more accurate method to come up with meaningful periodisation for a given dataset: Variability-based Neighbor Clustering (VNC). It is similar to hierarchical cluster analysis (HCA), i.e. a method that displays a hierarchy of clusters, typically in the form of dendrograms with branches and leaves. Differently from HCA, VNC does justice to the chronological linearity of linguistic developments by not separating adjacent periods, and shows significant differences between periods based on the standard deviation, which is taken as similarity measure and averaging as amalgamation rule.\nThe analyst needs to input the proportions of a given variant (in our case, causal uses) for periods, ideally decades. The choice of the periods size is somewhat arbitrary, but making different attempts helps to find the right balance between data sparsity and significance of the VNC results. Because at various points in the diachrony of our dataset data are scarce (see Histogram), we started with periods of 20 years and ended up with periods of 70 years. The VNC periodisation based on periods of 70 years is the one with the best results in statistical terms, as the standard deviation measure for different periods are large enough to show significant differences. Hereby we show the procedure.\n\nggplot(romall, aes(x=year, fill=semantics)) +\n  geom_histogram(alpha = 0.5, position=\"stack\") +\n  facet_wrap(~stringr::str_to_title(language))+\n  scale_fill_manual(labels=c(\"Causal\", \"Noncausal\"), values= (c(\"#fc8961\", \"#b73779\")))+   theme_minimal()\n\n\n\n\n\n\n\n\n\nEstablish the 70-years periodisation\n\nStep 1: Split the Italian and Spanish dataset.\n\n\n# Step 1\nesp &lt;- filter(romall, language==\"spanish\")\nita &lt;- filter(romall, language==\"italian\")\n\nThe range of years in the italian dataset is 1200, 1968 and for Spanish 1140, 2001.\n\nStep 2: Create a new variable with the years groups in 70-years periods. Periods are indicated with the central years in the 70 years span, i.e. 1175 stands for the period between 1140 and 1210.\nStep 3: Create a table with proportions of causal and noncausal uses by 70-years periods\n\n\n# Step 2\nesp&lt;-esp %&gt;% \n  mutate(\n    period70_es=case_when(\n      year&lt;1210 ~ \"1175\",\n      year&lt;1280 ~ \"1245\",\n      year&lt;1350 ~ \"1315\", \n      year&lt;1420 ~ \"1385\", \n      year&lt;1490 ~ \"1455\",\n      year&lt;1560 ~ \"1525\",\n      year&lt;1630 ~ \"1595\",\n      year&lt;1700 ~ \"1665\",\n      year&lt;1770 ~ \"1735\",\n      year&lt;1840 ~ \"1805\",\n      year&lt;1910 ~ \"1875\",\n      year&lt;1980 ~ \"1945\",\n      year&lt;=2001 ~ \"1990\"\n    )\n  )\n\nita&lt;-ita %&gt;% \n  mutate(\n    period70_ita=case_when(\n      year&lt;1270 ~ \"1235\",\n      year&lt;1340 ~ \"1305\",\n      year&lt;1410 ~ \"1375\", \n      year&lt;1480 ~ \"1445\", \n      year&lt;1550 ~ \"1515\",\n      year&lt;1620 ~ \"1585\",\n      year&lt;1690 ~ \"1655\",\n      year&lt;1760 ~ \"1725\",\n      year&lt;1830 ~ \"1795\",\n      year&lt;1900 ~ \"1865\",\n      year&lt;1970 ~ \"1935\"\n    )\n  )\n\n# Step 3\n\nes_perctable70&lt;-table(esp$period70_es,esp$semantics)\nes_perctable70&lt;-prop.table(es_perctable70,1)*100\nes_perctable70&lt;-as.data.frame(es_perctable70)\n\nita_perctable70&lt;-table(ita$period70_ita,ita$semantics)\nita_perctable70&lt;-prop.table(ita_perctable70,1)*100 \nita_perctable70&lt;-as.data.frame(ita_perctable70)\n\n\n\nApply the Variability neighbour clustering (VNC)\n\nStep 1: read the VNC instructions and download the VNC file at this link\nStep 2: Rename the columns following the instructions from the website\nStep 3: visualise input table for VNC and print it as a txt file\n\n\n# Step 2\n\nes_perctable70&lt;-filter(es_perctable70, Var2== \"caus\") %&gt;% \n  rename(year = Var1,input = Freq) %&gt;% \n  select(year, input) \n\nita_perctable70&lt;-filter(ita_perctable70, Var2== \"caus\") %&gt;% \n  rename(year = Var1,input = Freq) %&gt;% \n  select(year, input) \n\n#round up the proportions  \ntable_ita&lt;-ita_perctable70\ntable_ita$input&lt;-round(table_ita$input, digits = 1) \n\ntable_es&lt;-es_perctable70\ntable_es$input&lt;-round(table_es$input, digits = 1) \n\n#Step 3\n\ntable_ita %&gt;% \n  kbl(booktabs = TRUE, col.names = c(\"% Causal uses - Italian\", paste0(\"70 years periods\", footnote_marker_symbol(1))), escape = F, caption = \"Input table for the VNC\") %&gt;% \n  kable_styling()  %&gt;% \n  footnote(symbol = \"Periods are indicated with the central years in the 70 years span, i.e. 1175 stands for the period between 1140 and 1210\")\n\n\nInput table for the VNC\n\n\n% Causal uses - Italian\n70 years periods*\n\n\n\n\n1235\n61.7\n\n\n1305\n63.7\n\n\n1375\n63.5\n\n\n1445\n70.6\n\n\n1515\n73.6\n\n\n1585\n67.5\n\n\n1655\n61.4\n\n\n1725\n66.7\n\n\n1795\n63.0\n\n\n1865\n61.8\n\n\n1935\n60.4\n\n\n\n* Periods are indicated with the central years in the 70 years span, i.e. 1175 stands for the period between 1140 and 1210\n\n\n\n\n\n\n\n\ntable_es %&gt;% \n  kbl(booktabs = TRUE, col.names = c(\"% Causal uses - Spanish\", paste0(\"70 years periods\", footnote_marker_symbol(1))), escape = F, caption = \"Input table for the VNC\") %&gt;% \n  kable_styling()  %&gt;% \n  footnote(symbol = \"Periods are indicated with the central years in the 70 years span, i.e. 1175 stands for the period between 1140 and 1210\")\n\n\nInput table for the VNC\n\n\n% Causal uses - Spanish\n70 years periods*\n\n\n\n\n1175\n57.1\n\n\n1245\n53.7\n\n\n1315\n58.5\n\n\n1385\n73.0\n\n\n1455\n56.5\n\n\n1525\n56.6\n\n\n1595\n55.2\n\n\n1665\n62.8\n\n\n1735\n49.6\n\n\n1805\n51.7\n\n\n1875\n50.5\n\n\n1945\n52.0\n\n\n1990\n57.6\n\n\n\n* Periods are indicated with the central years in the 70 years span, i.e. 1175 stands for the period between 1140 and 1210\n\n\n\n\n\n\n\n\nsetcolorder (table_es, c(\"input\", \"year\"))\nwrite.table(table_es, file = \"esp_vnc_caus_70y_p.txt\", sep = \"\\t\", quote = FALSE, row.names = F)\n\nsetcolorder (table_ita, c(\"input\", \"year\"))\nwrite.table(table_ita, file = \"ita_vnc_caus_70y_p.txt\", sep = \"\\t\", quote = FALSE, row.names = F)\n\n\nStep 4: enter vnc.individual(file.choose()) and, when prompted to choose/enter a file name, choose/enter the path to the file with the data to be analyzed on the harddrive (e.g. newdata.txt). Run this in a separate R script and follow the instructions on the console.\n\n\n#do not run\n\nload(\"vnc.individual.RData\")\n\nvtxtnc.individual(\"esp_vnc_caus_70y_p.txt\")\n\nload(\"VNC/vnc.individual.RData\")\n\nvnc.individual(\"VNC/ita_vnc_caus_70y.txt\")\n\nRunning the previous script will generate two graphs in separate windows: a dendrogram and a screeplot of the type shown below.\nThe dendogram specifies how periods are clustered (the periods that are the most similar are amalgamated first). The analyst should asses how many development stages are considered relevant to the diachronic study. The screeplot produced by the VNC function allows the linguist to decide by comparing the distances between successive mergers (measured with standard deviations). Essentially, one should observe the slope from left to right, and take the number of clusters with the largest differences, until the slope is leveled off (i.e., until the difference between clusters is marginal). In this case 4 or 6 clusters seems adequate. Given that we want to minimise data sparsity, we make the most parsimonious choice and select the first 4 clusters.\n\n\n\nDendogram and Scree plot Italian\n\n\n From the interpretation of the VNC results we end up with 4 significant periods for the development of the causal vs. non causal alternation in Spanish, dividing our dataset in the following periods: 1140-1209,1210-1279, 1280-1559, 1560-2001. Data are distributed across periods as summarised below. In Spanish causal uses are consistently higher than noncausal ones, but always below 60% except in the second period where they reach 73%.\n\nesp&lt;-esp %&gt;% \n  mutate(\n    es_vnc70_apr25=case_when(\n      year&lt;1350 ~ \"1140-1349\",\n      year&lt;1420 ~ \"1350-1419\",\n      year&lt;1700 ~ \"1420-1699\",\n      year&lt;2002 ~ \"1700-2001\"\n    )\n  )\n\nsummary_es&lt;-esp %&gt;%\n  group_by (es_vnc70_apr25, semantics) %&gt;%\n  summarise (n=n()) %&gt;%\n  mutate(rel.freq = paste0(round(100 * n/sum(n), 0), \"%\"))\n\nsummary_es %&gt;%  kbl(booktabs = TRUE, col.names = c(\"VNC periods\", \"Semantics\", \"Count\", \"Relative Frequency (%)\"), caption = \"Spanish - Summary of the verb semantics by VNC periods\") %&gt;%\n   collapse_rows(column = 1) %&gt;% \n  kable_styling() \n\n\nSpanish - Summary of the verb semantics by VNC periods\n\n\nVNC periods\nSemantics\nCount\nRelative Frequency (%)\n\n\n\n\n1140-1349\ncaus\n434\n55%\n\n\nnoncaus\n348\n45%\n\n\n1350-1419\ncaus\n92\n73%\n\n\nnoncaus\n34\n27%\n\n\n1420-1699\ncaus\n1367\n57%\n\n\nnoncaus\n1044\n43%\n\n\n1700-2001\ncaus\n1653\n52%\n\n\nnoncaus\n1523\n48%\n\n\n\n\n\n\n\nFor Italian, the relevant 4 periods indicated by the dendogram are 1200-1409, 1410-1549, 1550-1619 and 1620-1968, Data are distributed across periods as summarised below. In Italian, causal uses are consistently more frequent than non causal ones, always higher than 60%. Their relative frequency is at the highest in the second period, when they reach 73%, like in Spanish. However, the second VNC period in Italian is about a century later than in Spanish.\n\nita&lt;-ita %&gt;% \n  mutate(\n    ita_vnc70_apr25=case_when(\n      year&lt;1410 ~ \"1200-1409\",\n      year&lt;1550 ~ \"1410-1549\",\n      year&lt;1620 ~ \"1550-1619\",\n      year&lt;=1970 ~ \"1620-1968\"\n    )\n  )\n\nsummary_ita&lt;-ita %&gt;%\n  group_by (ita_vnc70_apr25, semantics) %&gt;%\n  summarise (n=n()) %&gt;%\n  mutate(rel.freq = paste0(round(100 * n/sum(n), 0), \"%\"))\n\nsummary_ita %&gt;%  kbl(booktabs = TRUE, col.names = c(\"VNC periods\", \"Semantics\", \"Count\", \"Relative Frequency (%)\"), caption = \"Italian - Summary of the verb semantics by VNC periods\") %&gt;%\n   collapse_rows(column = 1) %&gt;% \n  kable_styling() \n\n\nItalian - Summary of the verb semantics by VNC periods\n\n\nVNC periods\nSemantics\nCount\nRelative Frequency (%)\n\n\n\n\n1200-1409\ncaus\n768\n64%\n\n\nnoncaus\n441\n36%\n\n\n1410-1549\ncaus\n1135\n73%\n\n\nnoncaus\n421\n27%\n\n\n1550-1619\ncaus\n695\n67%\n\n\nnoncaus\n335\n33%\n\n\n1620-1968\ncaus\n2700\n62%\n\n\nnoncaus\n1635\n38%"
  },
  {
    "objectID": "causal_freq_full_code_dec25.html#calculate-the-causalness-degree",
    "href": "causal_freq_full_code_dec25.html#calculate-the-causalness-degree",
    "title": "Causalness, frequency, diachrony and the causal-noncausal alternation in Italian and Spanish",
    "section": "Calculate the Causalness Degree",
    "text": "Calculate the Causalness Degree\nOnce we found out the significant periods for the causal/non causal alternation, we calculate the share of causal uses by verb lemma and by period. Namely, every verb lemma in each of the four periods is assigned a number between 0 and 1, indicating the proportion (%) of causal uses vs. non causal uses. The table below summarises the distribution of causal uses by lemma and period (variable caus_use).\nItalian:\n\ncaus_use_ita&lt;-ita %&gt;%\n  group_by (ita_vnc70_apr25, lemma, semantics) %&gt;%\n  summarise (n=n()) %&gt;%\n  mutate(caus_use_ita_apr25 = n/sum(n))\n\n\ncaus_use_ita&lt;-caus_use_ita %&gt;% filter(semantics==\"caus\") %&gt;% ungroup() %&gt;% select (-semantics)\n\ncaus_use_ita %&gt;% DT::datatable(rownames=F, filter=\"top\")\n\n\n\n\n\nSpanish:\n\ncaus_use_es &lt;-esp %&gt;%\n  group_by (es_vnc70_apr25, lemma, semantics) %&gt;%\n  summarise (n=n()) %&gt;%\n  mutate(caus_use_es_apr25 = n/sum(n))\n\n\ncaus_use_es&lt;-caus_use_es %&gt;% filter(semantics==\"caus\") %&gt;% ungroup() %&gt;% select (-semantics)\n\ncaus_use_es %&gt;% DT::datatable(rownames=F, filter=\"top\")\n\n\n\n\n\nAnd finally rejoin the individual languages new information (period70, vnc and causalness degree) to the main dataset:\n\n# 1. Join caus_use_ita to ita by vnc and lemma\nita &lt;- ita %&gt;%\n  left_join(caus_use_ita, by = c(\"ita_vnc70_apr25\" = \"ita_vnc70_apr25\", \"lemma\" = \"lemma\"))\n\n# 2. Join caus_use_es to esp by vnc and lemma\nesp &lt;- esp %&gt;%\n  left_join(caus_use_es, by = c(\"es_vnc70_apr25\" = \"es_vnc70_apr25\", \"lemma\" = \"lemma\"))\n\nnames(ita)[duplicated(names(ita))]\n\ncharacter(0)\n\n# 3. Rename columns to match target names before merging into romall\nita &lt;- ita %&gt;%\n  select(-any_of(c(\"vnc_period_apr25\", \"causalness_degree_apr25\"))) %&gt;%\n  rename(\n    vnc_period_apr25 = ita_vnc70_apr25,\n    causalness_degree_apr25 = caus_use_ita_apr25\n  )\n\nesp &lt;- esp %&gt;%\n  select(-any_of(c(\"vnc_period_apr25\", \"causalness_degree_apr25\"))) %&gt;%\n  rename(\n    vnc_period_apr25 = es_vnc70_apr25,\n    causalness_degree_apr25 = caus_use_es_apr25\n  )\n\n# 4. Bind the two enriched subsets together\ncombined &lt;- bind_rows(ita, esp)\n\n# 5. Join back to romall by id and lemma\nromall &lt;- romall %&gt;%\n  select(-any_of(c(\"vnc_period_apr25\", \"causalness_degree_apr25\"))) %&gt;%\n  left_join(combined %&gt;% select(id, lemma, vnc_period_apr25, causalness_degree_apr25),\n            by = c(\"id\", \"lemma\"))\n\n\nnc &lt;- nc %&gt;%\n  select(-any_of(c(\"vnc_period_apr25\", \"causalness_degree_apr25\"))) %&gt;%\n  left_join(combined %&gt;% select(id, lemma, vnc_period_apr25, causalness_degree_apr25),\n            by = c(\"id\", \"lemma\"))\n\n\n#only run this if you want to save the results of the VNC in a new xlsx file\n\nopenxlsx::write.xlsx(romall, \"romall_new_VNC.xlsx\")\nopenxlsx::write.xlsx(nc, \"noncaus_new_VNC.xlsx\")"
  },
  {
    "objectID": "causal_freq_full_code_dec25.html#diachronic-analysis-of-the-noncausal-usage-and-causalness-degree-correlation",
    "href": "causal_freq_full_code_dec25.html#diachronic-analysis-of-the-noncausal-usage-and-causalness-degree-correlation",
    "title": "Causalness, frequency, diachrony and the causal-noncausal alternation in Italian and Spanish",
    "section": "Diachronic analysis of the noncausal usage and causalness degree correlation",
    "text": "Diachronic analysis of the noncausal usage and causalness degree correlation\nAfter calculating the diachronic causalness degree, we follow the procedure outlined in Heidinger (2015). For each verb in the two languages, we measure its correlation with the percentage of anticausative marking, iterating the count separately for each of the four periods. The results are shown in Figure 6 and Figure 7:\n\n##Calculate causalness degree by language and period\n\ncaus_degree_ita &lt;- romall %&gt;%\n  filter (language == 'italian') %&gt;%\n  group_by(meaning, vnc_period_apr25) %&gt;%\n  summarise(caus_degree = sum(semantics == 'caus') * 100 / n())\n\ncaus_degree_es &lt;- romall %&gt;%\n  filter (language == 'spanish') %&gt;%\n  group_by(meaning, vnc_period_apr25) %&gt;%\n  summarise(caus_degree = sum(semantics == 'caus') * 100 / n())\n\n##Calculate percentage of anticausative marking by language and period\n\ncoding_percentages_ita &lt;- romall %&gt;%\n  group_by(meaning, semantics, coding, vnc_period_apr25) %&gt;%\n  filter (language == 'italian') %&gt;%\n  summarise(count = n()) %&gt;%\n  spread(coding, count, fill = 0) %&gt;%\n  mutate(caus_degree_vs_zero = caus * 100 / (caus + zero),\n         prop_antic_vs_zero = antic * 100 / (antic + zero))\n  \n\ncoding_percentages_es &lt;- romall %&gt;%\n  group_by(meaning, semantics, coding, vnc_period_apr25) %&gt;%\n  filter (language == 'spanish') %&gt;%\n  summarise(count = n()) %&gt;%\n  spread(coding, count, fill = 0) %&gt;%\n  mutate(caus_degree_vs_zero = caus * 100 / (caus + zero),\n         prop_antic_vs_zero = antic * 100 / (antic + zero))\n\n##Scatter Plot of correlations between causalness degree and anticausative marking by period and language\n\nmerged_data_ita &lt;- merge(caus_degree_ita, coding_percentages_ita, by = c(\"meaning\", \"vnc_period_apr25\"))\n\nmerged_data_ita_noncaus &lt;- merged_data_ita %&gt;%\n  filter(semantics == 'noncaus')\n\nmerged_data_ita_noncaus_1 &lt;- merged_data_ita_noncaus %&gt;%\n  filter(vnc_period_apr25 == '1200-1409')\n\nmerged_data_ita_noncaus_2 &lt;- merged_data_ita_noncaus %&gt;%\n  filter(vnc_period_apr25 == '1410-1549')\n\nmerged_data_ita_noncaus_3 &lt;- merged_data_ita_noncaus %&gt;%\n  filter(vnc_period_apr25 == '1550-1619')\n\nmerged_data_ita_noncaus_4 &lt;- merged_data_ita_noncaus %&gt;%\n  filter(vnc_period_apr25 == '1620-1968')\n\nmerged_data_es &lt;- merge(caus_degree_es, coding_percentages_es, by = c(\"meaning\", \"vnc_period_apr25\"))\n\nmerged_data_es_noncaus &lt;- merged_data_es %&gt;%\n  filter(semantics == 'noncaus')\n\nmerged_data_es_noncaus_1 &lt;- merged_data_es_noncaus %&gt;%\n  filter(vnc_period_apr25 == '1140-1349')\n\nmerged_data_es_noncaus_2 &lt;- merged_data_es_noncaus %&gt;%\n  filter(vnc_period_apr25 == '1350-1419')\n\nmerged_data_es_noncaus_3 &lt;- merged_data_es_noncaus %&gt;%\n  filter(vnc_period_apr25 == '1420-1699')\n\nmerged_data_es_noncaus_4 &lt;- merged_data_es_noncaus %&gt;%\n  filter(vnc_period_apr25 == '1700-2001')\n\nplot_ita_1 &lt;- ggplot(merged_data_ita_noncaus_1, aes(x = caus_degree, y = prop_antic_vs_zero, label = meaning)) +\n  geom_point() +\n  labs(x = \"Causalness\",\n       y = \"%anticausative\", title = \"1200-1409\") +\n  theme_minimal() +\n  theme(text = element_text(size = 14))\n\nplot_ita_2 &lt;- ggplot(merged_data_ita_noncaus_2, aes(x = caus_degree, y = prop_antic_vs_zero, label = meaning)) +\n  geom_point() +\n  labs(x = \"Causalness\",\n       y = \"%anticausative\", title = \"1410-1549\") +\n  theme_minimal() +\n  theme(text = element_text(size = 14))\n\nplot_ita_3 &lt;- ggplot(merged_data_ita_noncaus_3, aes(x = caus_degree, y = prop_antic_vs_zero, label = meaning)) +\n  geom_point() +\n  labs(x = \"Causalness\",\n       y = \"%anticausative\", title = \"1550-1619\") +\n  theme_minimal() +\n  theme(text = element_text(size = 14))\n\nplot_ita_4 &lt;- ggplot(merged_data_ita_noncaus_4, aes(x = caus_degree, y = prop_antic_vs_zero, label = meaning)) +\n  geom_point() +\n  labs(x = \"Causalness\",\n       y = \"%anticausative\", title = \"1620-1968\") +\n  theme_minimal() +\n  theme(text = element_text(size = 14))\n\ngrid.arrange(plot_ita_1, plot_ita_2, plot_ita_3, plot_ita_4, nrow = 2, ncol = 2,  top = \"Italian Correlation Plot\")\n\n\n\n\n\n\n\n##Script for Figure 7\nplot_es_1 &lt;- ggplot(merged_data_es_noncaus_1, aes(x = caus_degree, y = prop_antic_vs_zero, label = meaning)) +\n  geom_point() +\n  labs(x = \"Causalness\",\n       y = \"%anticausative\", title = \"1140-1349\") +\n  theme_minimal() +\n  theme(text = element_text(size = 14))\n\nplot_es_2 &lt;- ggplot(merged_data_es_noncaus_2, aes(x = caus_degree, y = prop_antic_vs_zero, label = meaning)) +\n  geom_point() +\n  labs(x = \"Causalness\",\n       y = \"%anticausative\", title = \"1350-1419\") +\n  theme_minimal() +\n  theme(text = element_text(size = 14))\n\nplot_es_3 &lt;- ggplot(merged_data_es_noncaus_3, aes(x = caus_degree, y = prop_antic_vs_zero, label = meaning)) +\n  geom_point() +\n  labs(x = \"Causalness\",\n       y = \"%anticausative\", title = \"1420-1699\") +\n  theme_minimal() +\n  theme(text = element_text(size = 14))\n\nplot_es_4 &lt;- ggplot(merged_data_es_noncaus_4, aes(x = caus_degree, y = prop_antic_vs_zero, label = meaning)) +\n  geom_point() +\n  labs(x = \"Causalness\",\n       y = \"%anticausative\", title = \"1700-2001\") +\n  theme_minimal() +\n  theme(text = element_text(size = 14))\n\ngrid.arrange(plot_es_1, plot_es_2, plot_es_3, plot_es_4, nrow = 2, ncol = 2,  top = \"Spanish Correlation Plot\")\n\n\n\n\n\n\n\n\nThe corresponding correlation measures (Spearman Correlation Coefficient, SCC), alongside with p-values and the number of tokens analyzed for each period are given in the tables below:\n\n## Function to format the p-values\nformat_pval &lt;- function(p) {\n  case_when(\n    p &lt; 0.001 ~ \"&lt; 0.001***\",\n    p &lt; 0.01  ~ \"&lt; 0.01**\",\n    p &lt; 0.05  ~ \"&lt; 0.05*\",\n    TRUE      ~ paste0(\"= \", round(p, 2))\n  )\n}\n\n# Italian\n\n## Individual periods datasets for Italian\ndatasets &lt;- list(\n  Period1 = merged_data_ita_noncaus_1,\n  Period2 = merged_data_ita_noncaus_2,\n  Period3 = merged_data_ita_noncaus_3,\n  Period4 = merged_data_ita_noncaus_4\n)\n\n## Make a dataframe with the Spearman correlation and p-values\ncor_table_ita &lt;- purrr::imap_dfr(datasets, function(df, period) {\n  test_result &lt;- cor.test(df$caus_degree, df$prop_antic_vs_zero, method = \"spearman\", exact = FALSE)\n  \n  tibble(\n    Period = period,\n    Spearman_Correlation = round(test_result$estimate, 2),\n    P_value = format_pval(test_result$p.value)\n  )\n})\n\n## Show with kableExtra\ncor_table_ita %&gt;%\n  kable(\"html\", caption = \"Italian - Spearman Correlation Between Causalness Degree and Anticausative Usage by Period\") %&gt;%\n  kable_styling(full_width = FALSE, bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\nItalian - Spearman Correlation Between Causalness Degree and Anticausative Usage by Period\n\n\nPeriod\nSpearman_Correlation\nP_value\n\n\n\n\nPeriod1\n0.28\n= 0.24\n\n\nPeriod2\n0.79\n&lt; 0.001***\n\n\nPeriod3\n0.58\n&lt; 0.01**\n\n\nPeriod4\n0.59\n&lt; 0.01**\n\n\n\n\n\n\n# Spanish\n\n## Individual periods datasets for Italian\ndatasets_es &lt;- list(\n  Period1 = merged_data_es_noncaus_1,\n  Period2 = merged_data_es_noncaus_2,\n  Period3 = merged_data_es_noncaus_3,\n  Period4 = merged_data_es_noncaus_4\n)\n\n## Make a dataframe with the Spearman correlation and p-values\ncor_table_es &lt;- purrr::imap_dfr(datasets_es, function(df, period) {\n  test_result &lt;- cor.test(df$caus_degree, df$prop_antic_vs_zero, method = \"spearman\", exact = FALSE)\n  \n  tibble(\n    Period = period,\n    Spearman_Correlation = round(test_result$estimate, 2),\n    P_value = format_pval(test_result$p.value)\n  )\n})\n\n## Show with KableExtra\ncor_table_es %&gt;%\n  kable(\"html\", caption = \"Spearman Correlation Between Causalness and Anticausative Usage by Period (Spanish)\") %&gt;%\n  kable_styling(full_width = FALSE, bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\nSpearman Correlation Between Causalness and Anticausative Usage by Period (Spanish)\n\n\nPeriod\nSpearman_Correlation\nP_value\n\n\n\n\nPeriod1\n0.36\n= 0.22\n\n\nPeriod2\n0.43\n= 0.19\n\n\nPeriod3\n0.04\n= 0.88\n\n\nPeriod4\n0.15\n= 0.52\n\n\n\n\n\n\n\n\nLexical or semantic effects?\nThe correlations discussed above are based on verb meaning, but we maintain that it is important to also discuss lemma-effects.\nIn particular, if the degree of causalness were a direct consequence of the degree of spontaneity of the event (Heidinger 2015), we would expect verbs that lexicalize the same event (and therefore presumably share the same degree of spontaneity) to have substantially the same causalness degree. We have verified whether this is the case by looking at the Italian data for period IV.\n\n# Step 1: Calculate causal degree for Italian lemmas\ncaus_degree_ita_lemma &lt;- romall %&gt;%\n  filter(language == \"italian\") %&gt;%\n  group_by(lemma, vnc_period_apr25) %&gt;%\n  summarise(caus_degree = sum(semantics == \"caus\") * 100 / n(), .groups = \"drop\")\n\n# Step 2: Calculate coding percentages\ncoding_percentages_ita_lemma &lt;- romall %&gt;%\n  filter(language == \"italian\") %&gt;%\n  group_by(lemma, semantics, coding, vnc_period_apr25) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  pivot_wider(names_from = coding, values_from = count, values_fill = 0) %&gt;%\n  mutate(\n    caus_degree_vs_zero = caus * 100 / (caus + zero),\n    caus_degree_vs_zero = antic * 100 / (antic + zero)\n  )\n\n# Step 3: Merge the datasets\nmerged_data_ita_lemma &lt;- left_join(\n  caus_degree_ita_lemma,\n  coding_percentages_ita_lemma,\n  by = c(\"lemma\", \"vnc_period_apr25\")\n)\n\n# Step 4: Filter for noncausative semantics and specific time period\nmerged_data_ita_noncaus_4_lemma &lt;- merged_data_ita_lemma %&gt;%\n  filter(semantics == \"noncaus\", vnc_period_apr25 == \"1620-1968\")\n\n# Step 5: Create verb meaning groups\ngroupings &lt;- list(\n  burn = c(\"ardere\", \"bruciare\"),\n  fill = c(\"empiere\", \"riempire\"),\n  melt = c(\"sciogliere\", \"fondere\"),\n  rise = c(\"alzare\", \"sollevare\"),\n  rock = c(\"dondolare\", \"oscillare\"),\n  split = c(\"dividere\", \"separare\"),\n  stop = c(\"arrestare\", \"fermare\")\n  )\n\n# Assign group labels\nmerged_data_ita_noncaus_4_lemma &lt;- merged_data_ita_noncaus_4_lemma %&gt;%\n  mutate(group = map_chr(lemma, function(l) {\n    matched_group &lt;- names(keep(groupings, ~ l %in% .x))\n    if (length(matched_group) &gt; 0) matched_group else NA_character_\n  })) %&gt;%\n  filter(!is.na(group)) %&gt;%\n  mutate(group = factor(group, levels = names(groupings)))\n\n# Step 6: Plot\nggplot(merged_data_ita_noncaus_4_lemma, aes(\n  x = caus_degree,\n  y = caus_degree_vs_zero,\n  label = lemma,\n  color = group,\n  fill = group\n)) +\n  geom_point() +\n  geom_text_repel(\n    data = merged_data_ita_noncaus_4_lemma %&gt;%\n      filter(lemma %in% unlist(groupings)),\n    aes(color = group),\n    hjust = 0.5,\n    vjust = -0.5,\n    size = 4\n  ) +\n  labs(\n    x = \"Causalness\",\n    y = \"% Anticausative\"\n  ) +\n  theme_minimal() +\n  theme(text = element_text(size = 14)) +\n  scale_color_manual(\n    name = \"Meaning\",\n    values = c(\n      burn = \"red\", fill = \"blue\", melt = \"purple\", rise = \"brown\",\n      rock = \"green\", split = \"cyan\", stop = \"orange\"\n    )\n  ) +\n  scale_fill_manual(\n    name = \"Meaning\",\n    values = c(\n      burn = \"red\", fill = \"blue\", melt = \"purple\", rise = \"brown\",\n      rock = \"green\", split = \"cyan\", stop = \"orange\"\n    )\n  ) +\n  guides(color = guide_legend(override.aes = list(shape = 16, size = 4)))"
  },
  {
    "objectID": "causal_freq_full_code_dec25.html#italian-data-prepare-for-beta-regression",
    "href": "causal_freq_full_code_dec25.html#italian-data-prepare-for-beta-regression",
    "title": "Causalness, frequency, diachrony and the causal-noncausal alternation in Italian and Spanish",
    "section": "Italian data: prepare for Beta Regression",
    "text": "Italian data: prepare for Beta Regression\nSubset the Italian data to obtain unique combinations of lemma and period.\n\nStep 1: Aggregate data to calculate the proportion of anticausative codings\n\n\nita_agg &lt;- ita_nc %&gt;%\n  group_by(lemma, period) %&gt;%\n  summarise(\n    anticausative_count = sum(coding == \"antic\"),\n    total_count = n(),\n    proportion_anticausative = anticausative_count / total_count,\n    causalness_degree = first(causalness_degree),\n      ) %&gt;%\n  ungroup()\n\n\nStep 2: Create a lagged causalness_degree variable\n\n\nita_agg &lt;- ita_agg %&gt;%\n  arrange(lemma, period) %&gt;%\n  group_by(lemma) %&gt;%\n  mutate(causalness_lagged = lag(causalness_degree)) %&gt;%\n  ungroup() %&gt;%\n  # Remove rows without previous causalness_degree (period 1)\n  filter(!is.na(causalness_lagged))"
  },
  {
    "objectID": "causal_freq_full_code_dec25.html#spanish-data-prepare-for-beta-regression",
    "href": "causal_freq_full_code_dec25.html#spanish-data-prepare-for-beta-regression",
    "title": "Causalness, frequency, diachrony and the causal-noncausal alternation in Italian and Spanish",
    "section": "Spanish data: prepare for Beta Regression",
    "text": "Spanish data: prepare for Beta Regression\nSubset the Spanish data to obtain unique combinations of lemma and period.\n\nStep 1: Aggregate data to calculate the proportion of anticausative codings:\n\n\nes_agg &lt;- es_nc %&gt;%\n  group_by(lemma, period) %&gt;%\n  summarise(\n    anticausative_count = sum(coding == \"antic\"),\n    total_count = n(),\n    proportion_anticausative = anticausative_count / total_count,\n    causalness_degree = first(causalness_degree),\n    ) %&gt;%\n  ungroup()\n\n\nStep 2: Create a lagged causalness_degree variable:\n\n\nes_agg &lt;- es_agg %&gt;%\n  arrange(lemma, period) %&gt;%\n  group_by(lemma) %&gt;%\n  mutate(causalness_lagged = lag(causalness_degree)) %&gt;%\n  ungroup() %&gt;%\n  # Remove rows without previous causalness_degree (period 1)\n  filter(!is.na(causalness_lagged))"
  },
  {
    "objectID": "causal_freq_full_code_dec25.html#fit-the-beta-regression-model",
    "href": "causal_freq_full_code_dec25.html#fit-the-beta-regression-model",
    "title": "Causalness, frequency, diachrony and the causal-noncausal alternation in Italian and Spanish",
    "section": "Fit the Beta Regression model",
    "text": "Fit the Beta Regression model\n\nPrepare the data for the regression model\n\nStep 1: join the Italian and Spanish sub-dataset\nStep 2: make the categorical variable into factors; transform period into a numeric variable to be able to use it as a smooth term\nStep 3: handling proportions for beta regression and adjust the numeric variables\n\nIn our data, the dependent variable proportion_anticausative takes values between 0 and 1. However, some observations are exactly 0 or 1. This poses a problem for beta regression (and its GAM extension with family = betar), because the beta distribution is only defined on the open interval (0,1).\nTo address this, we applied a small adjustment:\nWe created a copy of the original variable (proportion_anticausative_notadj) to preserve the raw values, including 0s and 1s.\nWe replaced the original proportion_anticausative with a slightly modified version where values equal to 0 are nudged to a very small positive number (ε = 0.000001), and values equal to 1 are nudged to just below 1 (1 – ε).\nThis ensures that all proportions are strictly within (0,1), making them suitable for beta regression, while still preserving the original variable for transparency and reference.\n\n# Step 1\n## Add a column to each dataset to distinguish them\nitalian &lt;- ita_agg %&gt;%\n  mutate(language = \"Italian\")\n\nspanish &lt;- es_agg %&gt;%\n  mutate(language = \"Spanish\")\n\n## Combine the datasets using bind_rows()\njoin &lt;- bind_rows(italian, spanish)\n\n\n# Step 2: prepare factors variables\n\njoin$language&lt;-as.factor(join$language)\njoin$period_cat&lt;-as.factor(join$period)\njoin$period&lt;-as.factor(join$period)\n\njoin$period &lt;- as.numeric(join$period_cat)\n\n# Step 3: adjust the numeric variables to avoid exact 0s and 1s in the dependent variable and to make NAs into 0s for the predictors\n\n\nepsilon &lt;- 1e-6  # small adjustment so values fall strictly in (0,1)\n\njoin &lt;- join %&gt;%\n  mutate(\n    causalness_degree = ifelse(is.na(causalness_degree), 0, causalness_degree),\n    causalness_lagged = ifelse(is.na(causalness_lagged), 0, causalness_lagged),\n    proportion_anticausative_notadj = proportion_anticausative,  # keep original\n    proportion_anticausative = pmin(pmax(proportion_anticausative, epsilon), 1 - epsilon)  # adjusted\n  )\n\n# quick checks\nrange(join$proportion_anticausative_notadj, na.rm = TRUE)  # should still show 0 and 1\n\n[1] 0 1\n\nrange(join$proportion_anticausative, na.rm = TRUE)         # should now be (0,1)\n\n[1] 0.000001 0.999999\n\nall(join$proportion_anticausative &gt; 0 & join$proportion_anticausative &lt; 1)  # should be TRUE\n\n[1] TRUE\n\n\nHereby a summary of the dataset with only unique combinations of lemma and period and their anticausative count, proportion, synchronic and lagged causalness degree:\n\n# Summarize the dataset \n\nsummary_table &lt;- join %&gt;%\n  group_by(language, lemma, period_cat) %&gt;%\n  summarise(\n    N_Antic = sum(anticausative_count, na.rm = TRUE),   # Total count of anticausatives\n    N_Total = sum(total_count, na.rm = TRUE),             # Total count of all occurrences\n    `%_Antic_adjusted` = proportion_anticausative * 100,           # Directly use the original proportion value\n    Causalness_Degree = causalness_degree,                # Use the original value\n    Causalness_Lagged = causalness_lagged                 # Use the original value\n  ) %&gt;%\n  ungroup()  # Remove grouping\n\nsummary_table %&gt;%\n  kable(\"html\", caption = \"Summary Table of Anticausative Proportions by Language, Lemma, and Period\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"), full_width = F) %&gt;%\n  row_spec(0, bold = TRUE) %&gt;%  # Optional: make the header row bold\n  collapse_rows(columns = c(1, 2), valign = \"top\")  # Collapse the rows for language and lemma\n\n\nSummary Table of Anticausative Proportions by Language, Lemma, and Period\n\n\nlanguage\nlemma\nperiod_cat\nN_Antic\nN_Total\n%_Antic_adjusted\nCausalness_Degree\nCausalness_Lagged\n\n\n\n\nItalian\naffondare\n1410-1549\n0\n1\n0.000100\n0.5000000\n0.1250000\n\n\n1550-1619\n1\n2\n50.000000\n0.3333333\n0.5000000\n\n\n1620-1968\n5\n21\n23.809524\n0.1600000\n0.3333333\n\n\nalzare\n1410-1549\n14\n16\n87.500000\n0.8181818\n0.8214286\n\n\n1550-1619\n32\n32\n99.999900\n0.6404494\n0.8181818\n\n\n1620-1968\n155\n155\n99.999900\n0.5596591\n0.6404494\n\n\nardere\n1410-1549\n4\n95\n4.210526\n0.4946809\n0.5161290\n\n\n1550-1619\n2\n67\n2.985075\n0.3557692\n0.4946809\n\n\n1620-1968\n0\n86\n0.000100\n0.3722628\n0.3557692\n\n\narrestare\n1410-1549\n3\n3\n99.999900\n0.7857143\n0.1111111\n\n\n1550-1619\n6\n7\n85.714286\n0.5625000\n0.7857143\n\n\n1620-1968\n101\n104\n97.115385\n0.4057143\n0.5625000\n\n\nbruciare\n1550-1619\n1\n3\n33.333333\n0.5000000\n0.8750000\n\n\n1620-1968\n1\n30\n3.333333\n0.6202532\n0.5000000\n\n\nchiudere\n1410-1549\n11\n15\n73.333333\n0.8148148\n0.6739130\n\n\n1550-1619\n4\n4\n99.999900\n0.9090909\n0.8148148\n\n\n1620-1968\n38\n38\n99.999900\n0.8671329\n0.9090909\n\n\ndividere\n1410-1549\n14\n14\n99.999900\n0.9034483\n0.7826087\n\n\n1550-1619\n14\n14\n99.999900\n0.8271605\n0.9034483\n\n\n1620-1968\n51\n51\n99.999900\n0.8131868\n0.8271605\n\n\nfermare\n1410-1549\n43\n46\n93.478261\n0.4888889\n0.8000000\n\n\n1550-1619\n35\n35\n99.999900\n0.4262295\n0.4888889\n\n\n1620-1968\n172\n185\n92.972973\n0.2773438\n0.4262295\n\n\nfondere\n1410-1549\n1\n1\n99.999900\n0.8333333\n0.8235294\n\n\n1550-1619\n0\n2\n0.000100\n0.0000000\n0.8333333\n\n\ngelare\n1620-1968\n7\n31\n22.580645\n0.2954545\n0.5000000\n\n\ngirare\n1410-1549\n4\n34\n11.764706\n0.4137931\n0.1125828\n\n\n1550-1619\n5\n31\n16.129032\n0.4150943\n0.4137931\n\n\n1620-1968\n16\n146\n10.958904\n0.3209302\n0.4150943\n\n\nmigliorare\n1410-1549\n0\n6\n0.000100\n0.4545455\n0.7692308\n\n\n1550-1619\n0\n4\n0.000100\n0.6363636\n0.4545455\n\n\n1620-1968\n2\n23\n8.695652\n0.7500000\n0.6363636\n\n\nradunare\n1410-1549\n38\n39\n97.435897\n0.5851064\n0.6032609\n\n\n1550-1619\n15\n15\n99.999900\n0.6052632\n0.5851064\n\n\n1620-1968\n69\n72\n95.833333\n0.3513514\n0.6052632\n\n\nriempire\n1410-1549\n5\n5\n99.999900\n0.8148148\n0.8333333\n\n\n1550-1619\n2\n2\n99.999900\n0.8823529\n0.8148148\n\n\n1620-1968\n13\n13\n99.999900\n0.8859649\n0.8823529\n\n\nrompere\n1410-1549\n16\n16\n99.999900\n0.9030303\n0.8586957\n\n\n1550-1619\n6\n6\n99.999900\n0.8983051\n0.9030303\n\n\n1620-1968\n31\n35\n88.571429\n0.8241206\n0.8983051\n\n\nsciogliere\n1410-1549\n7\n7\n99.999900\n0.9078947\n0.9393939\n\n\n1550-1619\n5\n6\n83.333333\n0.9259259\n0.9078947\n\n\n1620-1968\n66\n67\n98.507463\n0.7803279\n0.9259259\n\n\nseccare\n1410-1549\n5\n9\n55.555556\n0.4705882\n0.7058824\n\n\n1550-1619\n4\n5\n80.000000\n0.1666667\n0.4705882\n\n\n1620-1968\n4\n7\n57.142857\n0.3636364\n0.1666667\n\n\nspegnere\n1410-1549\n31\n35\n88.571429\n0.7784810\n0.6716418\n\n\n1550-1619\n2\n4\n50.000000\n0.8918919\n0.7784810\n\n\n1620-1968\n53\n59\n89.830508\n0.6878307\n0.8918919\n\n\nsvegliare\n1410-1549\n11\n14\n78.571429\n0.5483871\n0.3750000\n\n\n1550-1619\n7\n8\n87.500000\n0.4666667\n0.5483871\n\n\n1620-1968\n57\n61\n93.442623\n0.5579710\n0.4666667\n\n\nunire\n1410-1549\n16\n16\n99.999900\n0.5789474\n0.8333333\n\n\n1550-1619\n38\n38\n99.999900\n0.5128205\n0.5789474\n\n\n1620-1968\n157\n159\n98.742138\n0.5470085\n0.5128205\n\n\nSpanish\nabrir\n1350-1419\n1\n1\n99.999900\n0.5000000\n0.9074074\n\n\n1420-1699\n9\n10\n90.000000\n0.9295775\n0.5000000\n\n\n1700-2001\n26\n27\n96.296296\n0.8732394\n0.9295775\n\n\nalzar\n1350-1419\n3\n4\n75.000000\n0.7777778\n0.5901639\n\n\n1420-1699\n32\n39\n82.051282\n0.8088235\n0.7777778\n\n\n1700-2001\n30\n34\n88.235294\n0.6761905\n0.8088235\n\n\napagar\n1420-1699\n22\n23\n95.652174\n0.7012987\n0.8750000\n\n\n1700-2001\n116\n116\n99.999900\n0.6013746\n0.7012987\n\n\ncerrar\n1420-1699\n6\n9\n66.666667\n0.9217391\n0.8064516\n\n\n1700-2001\n15\n18\n83.333333\n0.8875000\n0.9217391\n\n\ncongelar\n1700-2001\n17\n18\n94.444444\n0.2800000\n0.4242424\n\n\nderretir\n1420-1699\n49\n52\n94.230769\n0.5737705\n0.5000000\n\n\n1700-2001\n71\n73\n97.260274\n0.3539823\n0.5737705\n\n\ndespertar\n1350-1419\n2\n5\n40.000000\n0.2857143\n0.5416667\n\n\n1420-1699\n8\n88\n9.090909\n0.5368421\n0.2857143\n\n\n1700-2001\n43\n109\n39.449541\n0.4953704\n0.5368421\n\n\nfundir\n1420-1699\n12\n12\n99.999900\n0.5862069\n0.7857143\n\n\n1700-2001\n24\n24\n99.999900\n0.2941176\n0.5862069\n\n\ngirar\n1420-1699\n1\n15\n6.666667\n0.5000000\n0.4000000\n\n\n1700-2001\n6\n305\n1.967213\n0.2738095\n0.5000000\n\n\nhervir\n1420-1699\n4\n148\n2.702703\n0.2043011\n0.4400000\n\n\n1700-2001\n7\n118\n5.932203\n0.1259259\n0.2043011\n\n\nhundir\n1700-2001\n99\n100\n99.000000\n0.3630573\n0.2448980\n\n\njuntar\n1350-1419\n2\n2\n99.999900\n0.5000000\n0.6666667\n\n\n1420-1699\n157\n160\n98.125000\n0.4539249\n0.5000000\n\n\n1700-2001\n26\n26\n99.999900\n0.5272727\n0.4539249\n\n\nlevantar\n1350-1419\n4\n4\n99.999900\n0.0000000\n0.1803279\n\n\n1700-2001\n77\n80\n96.250000\n0.5348837\n0.3783784\n\n\nllenar\n1700-2001\n27\n28\n96.428571\n0.7971014\n0.7000000\n\n\nmejorar\n1350-1419\n2\n5\n40.000000\n0.1666667\n0.2287582\n\n\n1420-1699\n17\n40\n42.500000\n0.5402299\n0.1666667\n\n\n1700-2001\n9\n48\n18.750000\n0.6220472\n0.5402299\n\n\nparar\n1350-1419\n2\n2\n99.999900\n0.8181818\n0.5775862\n\n\n1420-1699\n43\n94\n45.744681\n0.3472222\n0.8181818\n\n\n1700-2001\n16\n38\n42.105263\n0.1363636\n0.3472222\n\n\nquemar\n1350-1419\n2\n2\n99.999900\n0.9310345\n0.8703704\n\n\n1420-1699\n38\n45\n84.444444\n0.7867299\n0.9310345\n\n\n1700-2001\n14\n17\n82.352941\n0.7118644\n0.7867299\n\n\nromper\n1420-1699\n16\n36\n44.444444\n0.7721519\n0.7777778\n\n\n1700-2001\n19\n52\n36.538461\n0.6645161\n0.7721519\n\n\nsecar\n1350-1419\n2\n4\n50.000000\n0.2000000\n0.4333333\n\n\n1420-1699\n76\n76\n99.999900\n0.2621359\n0.2000000\n\n\n1700-2001\n28\n29\n96.551724\n0.6233766\n0.2621359\n\n\n\n\n\n\n\n\n\nModel fit and model selection\nHereby we fit a beta regression model with mgvc::gam: model1 is the maximal model which includes\n\ns(causalness_degree, k=10), s(causalness_lagged, k=10) and s(period, k=5): global smooth terms — these model the overall nonlinear effects of each predictor across all languages.\ns(causalness_lagged, by = language, k = 10, bs = \"cs\", m = 1), s(causalness_degree, by = language, k = 10, bs = \"cs\", m = 1), and s(period, by = language, k = 5, bs = \"cs\", m= 1): group-wise smooths (by language) — these allow the shape of the smooth to differ between Italian and Spanish.\nfamily = betar(...): the model uses a beta regression family, designed for proportions or rates strictly between 0 and 1.\nlink = \"logit\": the logit link function ensures predicted values remain within the (0, 1) range.\nmethod = \"ML\": the model is fitted using maximum likelihood estimation (ML) rather than the default restricted maximum likelihood (REML). ML is typically used when comparing models with different fixed-effect structures, since REML estimates are not directly comparable across models with different smooth terms.\n\n\nmodel1 &lt;- gam(\n  proportion_anticausative ~ \n    s(causalness_lagged, k=10)+\n    s(causalness_degree, k=10)+\n    s(period, k=5)+\n    s(causalness_lagged, by = language, k = 10, bs = \"cs\", m = 1) +\n    s(causalness_degree, by = language, k = 10, bs = \"cs\", m = 1) +\n    s(period, by = language, k = 5, bs = \"cs\", m= 1),   \n  family = betar(link = \"logit\"),                 \n  data = join,\n  method=\"ML\"\n)\n\n# Summarize the model\nsummary(model1)\n\n\nFamily: Beta regression(0.536) \nLink function: logit \n\nFormula:\nproportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_degree, \n    k = 10) + s(period, k = 5) + s(causalness_lagged, by = language, \n    k = 10, bs = \"cs\", m = 1) + s(causalness_degree, by = language, \n    k = 10, bs = \"cs\", m = 1) + s(period, by = language, k = 5, \n    bs = \"cs\", m = 1)\n\nParametric coefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.7087     0.1304   5.435 5.49e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                                           edf Ref.df Chi.sq p-value    \ns(causalness_lagged)                 1.000e+00      1  1.171 0.27928    \ns(causalness_degree)                 1.000e+00      1 11.195 0.00082 ***\ns(period)                            1.000e+00      1  0.259 0.61071    \ns(causalness_lagged):languageItalian 7.500e-06      9  0.000 0.58048    \ns(causalness_lagged):languageSpanish 1.190e-04      9  0.000 0.59603    \ns(causalness_degree):languageItalian 1.088e-05      9  0.000 0.18367    \ns(causalness_degree):languageSpanish 1.299e+00      9  8.120 0.00261 ** \ns(period):languageItalian            7.832e-05      3  0.000 0.24791    \ns(period):languageSpanish            1.844e-05      3  0.000 0.21472    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.148   Deviance explained = 26.7%\n-ML = -302.44  Scale est. = 1         n = 99\n\n\n\nStep 3: Backward selection\n\nIn model2 we start by removing s(period, k=5)+, as it is the term with the highest pvalue. + anova(..., test=\"Chisq\") compares two nested GAM models (e.g., model1 and a simpler model2) using a likelihood ratio test (Chi-squared test) + AIC(): it calculates the AIC of the two models, which is a measure of model fit that balances goodness-of-fit with model complexity (penalizes overfitting)\nWe continue removing terms with high p-value, until we reach the most parsimonious model which is model4.\nThe anova shows is ok to remove the term.\n\nmodel2 &lt;- gam(\n  proportion_anticausative ~ \n    s(causalness_lagged, k=10)+\n    s(causalness_degree, k=10)+\n    #s(period, k=5)+\n    s(causalness_lagged, by = language, k = 10, bs = \"cs\", m = 1) +\n    s(causalness_degree, by = language, k = 10, bs = \"cs\", m = 1)+\n    s(period, by = language, k = 5, bs = \"cs\", m= 1),   \n  family = betar(link = \"logit\"),                 \n  data = join,\n  method=\"ML\"\n)\n\n# Summarize the model\nsummary(model2)\n\n\nFamily: Beta regression(0.536) \nLink function: logit \n\nFormula:\nproportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_degree, \n    k = 10) + s(causalness_lagged, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(causalness_degree, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(period, by = language, k = 5, bs = \"cs\", m = 1)\n\nParametric coefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.7104     0.1305   5.445 5.19e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                                           edf Ref.df Chi.sq  p-value    \ns(causalness_lagged)                 1.000e+00      1  1.129 0.288069    \ns(causalness_degree)                 1.000e+00      1 11.940 0.000549 ***\ns(causalness_lagged):languageItalian 4.501e-06      9  0.000 0.623366    \ns(causalness_lagged):languageSpanish 7.298e-05      9  0.000 0.634162    \ns(causalness_degree):languageItalian 5.413e-06      9  0.000 0.188334    \ns(causalness_degree):languageSpanish 1.322e+00      9  8.454 0.002208 ** \ns(period):languageItalian            5.765e-05      3  0.000 0.514120    \ns(period):languageSpanish            1.327e-01      3  0.177 0.244040    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.161   Deviance explained = 26.8%\n-ML = -302.32  Scale est. = 1         n = 99\n\nanova(model1, model2, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: proportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_degree, \n    k = 10) + s(period, k = 5) + s(causalness_lagged, by = language, \n    k = 10, bs = \"cs\", m = 1) + s(causalness_degree, by = language, \n    k = 10, bs = \"cs\", m = 1) + s(period, by = language, k = 5, \n    bs = \"cs\", m = 1)\nModel 2: proportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_degree, \n    k = 10) + s(causalness_lagged, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(causalness_degree, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(period, by = language, k = 5, bs = \"cs\", m = 1)\n  Resid. Df Resid. Dev       Df Deviance Pr(&gt;Chi)\n1    92.750    -609.35                           \n2    93.361    -609.48 -0.61183  0.12349         \n\nAIC(model1, model2)\n\n             df       AIC\nmodel1 6.774768 -595.8037\nmodel2 6.046560 -597.3836\n\n\nIn model3 we need to remove s(causalness_lagged, by = language, k = 10, bs = \"cs\", m = 1), as it is the term with the highest pvalue. Anova shows it’s not ok to remove.\n\nmodel3 &lt;- gam(\n  proportion_anticausative ~ \n    s(causalness_lagged, k=10)+\n    s(causalness_degree, k=10)+\n    #s(period, k=5)+\n    #s(causalness_lagged, by = language, k = 10, bs = \"cs\", m = 1) +\n    s(causalness_degree, by = language, k = 10, bs = \"cs\", m = 1)+\n    s(period, by = language, k = 5, bs = \"cs\", m= 1),   \n  family = betar(link = \"logit\"),                 \n  data = join,\n  method=\"ML\"\n)\n\n# Summarize the model\nsummary(model3)\n\n\nFamily: Beta regression(0.536) \nLink function: logit \n\nFormula:\nproportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_degree, \n    k = 10) + s(causalness_degree, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(period, by = language, k = 5, bs = \"cs\", m = 1)\n\nParametric coefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.7104     0.1305   5.445 5.19e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                                           edf Ref.df Chi.sq  p-value    \ns(causalness_lagged)                 1.000e+00      1  1.129 0.288085    \ns(causalness_degree)                 1.000e+00      1 11.940 0.000549 ***\ns(causalness_degree):languageItalian 7.061e-06      9  0.000 0.188330    \ns(causalness_degree):languageSpanish 1.322e+00      9  8.455 0.002208 ** \ns(period):languageItalian            1.505e-04      3  0.000 0.514117    \ns(period):languageSpanish            1.327e-01      3  0.177 0.244041    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.161   Deviance explained = 26.8%\n-ML = -302.32  Scale est. = 1         n = 99\n\nanova(model3, model2, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: proportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_degree, \n    k = 10) + s(causalness_degree, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(period, by = language, k = 5, bs = \"cs\", m = 1)\nModel 2: proportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_degree, \n    k = 10) + s(causalness_lagged, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(causalness_degree, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(period, by = language, k = 5, bs = \"cs\", m = 1)\n  Resid. Df Resid. Dev          Df   Deviance  Pr(&gt;Chi)    \n1    93.361    -609.48                                     \n2    93.361    -609.48 -0.00015192 -9.173e-05 0.0007147 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAIC(model3, model2) \n\n             df       AIC\nmodel3 6.046661 -597.3835\nmodel2 6.046560 -597.3836\n\n\nWe go back to model2 and in model4 we remove s(period, by = language, k = 5, bs = \"cs\", m= 1) which is the second next highest p-value. The comparison between model2 and model4 shows it is ok to remove this term.\n\nmodel4 &lt;- gam(\n  proportion_anticausative ~ \n    s(causalness_lagged, k=10)+\n    s(causalness_degree, k=10)+\n    #s(period, k=5)+\n    s(causalness_lagged, by = language, k = 10, bs = \"cs\", m = 1) +\n    s(causalness_degree, by = language, k = 10, bs = \"cs\", m = 1),\n    #s(period, by = language, k = 5, bs = \"cs\", m= 1),   \n  family = betar(link = \"logit\"),                 \n  data = join,\n  method=\"ML\"\n)\n# Summarize the model\nsummary(model4)\n\n\nFamily: Beta regression(0.535) \nLink function: logit \n\nFormula:\nproportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_degree, \n    k = 10) + s(causalness_lagged, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(causalness_degree, by = language, k = 10, bs = \"cs\", \n    m = 1)\n\nParametric coefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.7114     0.1304   5.456 4.86e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                                           edf Ref.df Chi.sq p-value   \ns(causalness_lagged)                 1.000e+00      1  1.177 0.27800   \ns(causalness_degree)                 1.000e+00      1  0.004 0.94653   \ns(causalness_lagged):languageItalian 2.142e-05      9  0.000 0.59328   \ns(causalness_lagged):languageSpanish 1.763e-05      9  0.000 0.60515   \ns(causalness_degree):languageItalian 1.345e+00      9  8.353 0.00243 **\ns(causalness_degree):languageSpanish 1.203e-05      9  0.000 0.14713   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.162   Deviance explained = 26.4%\n-ML = -302.15  Scale est. = 1         n = 99\n\nanova(model2, model4, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: proportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_degree, \n    k = 10) + s(causalness_lagged, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(causalness_degree, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(period, by = language, k = 5, bs = \"cs\", m = 1)\nModel 2: proportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_degree, \n    k = 10) + s(causalness_lagged, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(causalness_degree, by = language, k = 10, bs = \"cs\", \n    m = 1)\n  Resid. Df Resid. Dev       Df Deviance Pr(&gt;Chi)\n1    93.361    -609.48                           \n2    93.674    -609.11 -0.31242   -0.371   0.1941\n\nAIC(model2, model4)\n\n             df       AIC\nmodel2 6.046560 -597.3836\nmodel4 5.835506 -597.4347\n\n\nIn model5 we need to remove s(causalness_degree, k=10), as it is only marginally significant. Anova shows that removing it does not affect the model.\n\nmodel5 &lt;- gam(\n  proportion_anticausative ~ \n    s(causalness_lagged, k=10)+\n    #s(causalness_degree, k=10)+\n    #s(period, k=5)+\n    s(causalness_lagged, by = language, k = 10, bs = \"cs\", m = 1) +\n    s(causalness_degree, by = language, k = 10, bs = \"cs\", m = 1),\n    #s(period, by = language, k = 5, bs = \"cs\", m= 1),   \n  family = betar(link = \"logit\"),                 \n  data = join,\n  method=\"ML\"\n)\n# Summarize the model\nsummary(model5) \n\n\nFamily: Beta regression(0.535) \nLink function: logit \n\nFormula:\nproportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_lagged, \n    by = language, k = 10, bs = \"cs\", m = 1) + s(causalness_degree, \n    by = language, k = 10, bs = \"cs\", m = 1)\n\nParametric coefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.7121     0.1300   5.476 4.34e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                                           edf Ref.df Chi.sq  p-value    \ns(causalness_lagged)                 1.000e+00      1  1.507 0.219630    \ns(causalness_lagged):languageItalian 6.165e-05      9  0.000 0.614137    \ns(causalness_lagged):languageSpanish 4.849e-05      9  0.000 0.623972    \ns(causalness_degree):languageItalian 1.401e+00      9 13.356 0.000165 ***\ns(causalness_degree):languageSpanish 4.976e-05      9  0.000 0.673066    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.171   Deviance explained = 26.4%\n-ML = -302.15  Scale est. = 1         n = 99\n\nanova(model4, model5, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: proportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_degree, \n    k = 10) + s(causalness_lagged, by = language, k = 10, bs = \"cs\", \n    m = 1) + s(causalness_degree, by = language, k = 10, bs = \"cs\", \n    m = 1)\nModel 2: proportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_lagged, \n    by = language, k = 10, bs = \"cs\", m = 1) + s(causalness_degree, \n    by = language, k = 10, bs = \"cs\", m = 1)\n  Resid. Df Resid. Dev     Df  Deviance Pr(&gt;Chi)\n1    93.674    -609.11                          \n2    94.713    -609.04 -1.039 -0.066054   0.8105\n\nAIC(model4, model5) \n\n             df       AIC\nmodel4 5.835506 -597.4347\nmodel5 4.844266 -599.3511\n\n\nThe next candidate for removal is s(causalness_lagged) in model6 (as we tried already removing s(causalness_lagged, by = language, k = 10, bs = \"cs\", m = 1). It is not completely ok to remove that, because the anova is marginally significant and the AIC is lower for model5.\nSo we go back to model5 and this time in model7 we remove s(causalness_lagged, by = language, k = 10, bs = \"cs\", m = 1). It seems that model5 is our final model, as removing this group-wise smooth is not ok.\n\nmodel6 &lt;- gam(\n  proportion_anticausative ~ \n    #s(causalness_lagged, k=10)+\n    #s(causalness_degree, k=10)+\n    #s(period, k=5)+\n    s(causalness_lagged, by = language, k = 10, bs = \"cs\", m = 1) +\n    s(causalness_degree, by = language, k = 10, bs = \"cs\", m = 1),\n    #s(period, by = language, k = 5, bs = \"cs\", m= 1),   \n  family = betar(link = \"logit\"),                 \n  data = join,\n  method=\"ML\"\n)\n# Summarize the model\nsummary(model6) #\n\n\nFamily: Beta regression(0.53) \nLink function: logit \n\nFormula:\nproportion_anticausative ~ s(causalness_lagged, by = language, \n    k = 10, bs = \"cs\", m = 1) + s(causalness_degree, by = language, \n    k = 10, bs = \"cs\", m = 1)\n\nParametric coefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.7051     0.1303   5.411 6.26e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                                           edf Ref.df Chi.sq  p-value    \ns(causalness_lagged):languageItalian 3.147e-01      9  0.476    0.199    \ns(causalness_lagged):languageSpanish 1.549e-04      9  0.000    0.553    \ns(causalness_degree):languageItalian 1.464e+00      9 16.542 1.06e-05 ***\ns(causalness_degree):languageSpanish 5.403e-05      9  0.000    0.946    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.148   Deviance explained = 25.7%\n-ML = -301.38  Scale est. = 1         n = 99\n\nanova(model6, model5, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: proportion_anticausative ~ s(causalness_lagged, by = language, \n    k = 10, bs = \"cs\", m = 1) + s(causalness_degree, by = language, \n    k = 10, bs = \"cs\", m = 1)\nModel 2: proportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_lagged, \n    by = language, k = 10, bs = \"cs\", m = 1) + s(causalness_degree, \n    by = language, k = 10, bs = \"cs\", m = 1)\n  Resid. Df Resid. Dev      Df Deviance Pr(&gt;Chi)  \n1    94.929    -608.43                            \n2    94.713    -609.04 0.21632  0.60493  0.09856 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAIC(model6, model5) \n\n             df       AIC\nmodel6 4.424766 -599.5852\nmodel5 4.844266 -599.3511\n\nmodel7 &lt;- gam(\n  proportion_anticausative ~ \n    s(causalness_lagged, k=10)+\n    #s(causalness_degree, k=10)+\n    #s(period, k=5)+\n    #s(causalness_lagged, by = language, k = 10, bs = \"cs\", m = 1) +\n    s(causalness_degree, by = language, k = 10, bs = \"cs\", m = 1),\n    #s(period, by = language, k = 5, bs = \"cs\", m= 1),   \n  family = betar(link = \"logit\"),                 \n  data = join,\n  method=\"ML\"\n)\n# Summarize the model\nsummary(model5) #\n\n\nFamily: Beta regression(0.535) \nLink function: logit \n\nFormula:\nproportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_lagged, \n    by = language, k = 10, bs = \"cs\", m = 1) + s(causalness_degree, \n    by = language, k = 10, bs = \"cs\", m = 1)\n\nParametric coefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.7121     0.1300   5.476 4.34e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                                           edf Ref.df Chi.sq  p-value    \ns(causalness_lagged)                 1.000e+00      1  1.507 0.219630    \ns(causalness_lagged):languageItalian 6.165e-05      9  0.000 0.614137    \ns(causalness_lagged):languageSpanish 4.849e-05      9  0.000 0.623972    \ns(causalness_degree):languageItalian 1.401e+00      9 13.356 0.000165 ***\ns(causalness_degree):languageSpanish 4.976e-05      9  0.000 0.673066    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.171   Deviance explained = 26.4%\n-ML = -302.15  Scale est. = 1         n = 99\n\nanova(model5, model7, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: proportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_lagged, \n    by = language, k = 10, bs = \"cs\", m = 1) + s(causalness_degree, \n    by = language, k = 10, bs = \"cs\", m = 1)\nModel 2: proportion_anticausative ~ s(causalness_lagged, k = 10) + s(causalness_degree, \n    by = language, k = 10, bs = \"cs\", m = 1)\n  Resid. Df Resid. Dev         Df    Deviance  Pr(&gt;Chi)    \n1    94.713    -609.04                                     \n2    94.713    -609.04 -8.287e-05 -1.1564e-05 0.0004757 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAIC(model7, model5) \n\n             df       AIC\nmodel7 4.844210 -599.3512\nmodel5 4.844266 -599.3511"
  },
  {
    "objectID": "causal_freq_full_code_dec25.html#diagnostics-of-model5",
    "href": "causal_freq_full_code_dec25.html#diagnostics-of-model5",
    "title": "Causalness, frequency, diachrony and the causal-noncausal alternation in Italian and Spanish",
    "section": "Diagnostics of model5",
    "text": "Diagnostics of model5\n\n# --- 1. Basic GAM checks (smoothness, k-index, residuals) ---\ngam.check(model5)  \n\n\n\n\n\n\n\n\n\nMethod: ML   Optimizer: outer newton\nfull convergence after 10 iterations.\nGradient range [-5.252597e-05,-1.740295e-06]\n(score -302.1485 & scale 1).\nHessian positive definite, eigenvalue range [1.740291e-06,67.0835].\nModel rank =  46 / 46 \n\nBasis dimension (k) checking results. Low p-value (k-index&lt;1) may\nindicate that k is too low, especially if edf is close to k'.\n\n                                           k'      edf k-index p-value\ns(causalness_lagged)                 9.00e+00 1.00e+00    0.94    0.21\ns(causalness_lagged):languageItalian 9.00e+00 6.16e-05    0.94    0.24\ns(causalness_lagged):languageSpanish 9.00e+00 4.85e-05    0.94    0.22\ns(causalness_degree):languageItalian 9.00e+00 1.40e+00    1.03    0.57\ns(causalness_degree):languageSpanish 9.00e+00 4.98e-05    1.03    0.57\n\n# --- 2. Concurvity (nonlinear collinearity among smooths) ---\nconcurvity(model5, full = TRUE)\n\n              para s(causalness_lagged) s(causalness_lagged):languageItalian\nworst    0.4633079            1.0000000                            1.0000000\nobserved 0.4633079            1.0000000                            1.0000000\nestimate 0.4633079            0.9986535                            0.9193622\n         s(causalness_lagged):languageSpanish\nworst                               1.0000000\nobserved                            1.0000000\nestimate                            0.9536625\n         s(causalness_degree):languageItalian\nworst                               0.7057063\nobserved                            0.5251884\nestimate                            0.2893153\n         s(causalness_degree):languageSpanish\nworst                               0.6903573\nobserved                            0.5590216\nestimate                            0.3517013\n\n\nThe QQ plot of residuals (gam.check) showed that the observed residuals closely followed the expected theoretical quantiles, with only minor deviations in the tails, suggesting that the beta regression model adequately captured the distributional assumptions.\nThe residuals versus fitted values plot showed that most observations clustered around mid-range fitted values (≈0.5), with some vertical stacking due to repeated predicted values. Residuals were approximately centered around zero without strong systematic trends, suggesting no major violations of model assumptions.\nBasis dimension checks (k-index = 0.94–1.03, all p &gt; 0.2) indicated that the chosen number of knots (k = 10) was adequate, with no evidence of undersmoothing.\nConcurvity checks indicated very high redundancy between the main smooth of causalness_lagged and its by-language interactions (concurvity ≈ 0.92–1.0). This suggests that the shared and language-specific smooths are not easily separable, likely because the language-specific effects were negligible. This was already noted above. Concurvity among the causalness_degree smooths was low to moderate (≤ 0.56 observed), and therefore not considered problematic."
  },
  {
    "objectID": "causal_freq_full_code_dec25.html#visualise-the-results-model5",
    "href": "causal_freq_full_code_dec25.html#visualise-the-results-model5",
    "title": "Causalness, frequency, diachrony and the causal-noncausal alternation in Italian and Spanish",
    "section": "Visualise the results model5",
    "text": "Visualise the results model5\nVisualisation of the effect of causalness_lagged, causalness_lagged by language and causalness_degree by language of model5 (now renamed model).\nWhen plotting the group-wise interaction of causalness_lagged we see that Italian and Spanish essentially overlap. It is quite puzzling that the model selection suggested to keep it, as there is clearly no effect. We take it to mean that the real effect is the one of causalness_lagged by itself, it is capturing everything important. The group-specific smooths are essentially flat → not adding meaningful information. Statistically, the likelihood test picks up the tiniest difference, but for interpretation and visualization, it’s safe to consider them redundant.\n\nmodel &lt;- model5\n\n\n# ---- 1. Prediction grid for causalness_lagged (shared smooth) ----\nnewdata_lagged &lt;- tibble(\n  causalness_lagged = seq(min(join$causalness_lagged), max(join$causalness_lagged), length.out = 200),\n  causalness_degree = mean(join$causalness_degree, na.rm = TRUE),\n  language = factor(\"Italian\", levels = levels(join$language))  # shared smooth\n)\n\npred_lagged &lt;- predict(model, newdata_lagged, type = \"link\", se.fit = TRUE)\n\nnewdata_lagged &lt;- newdata_lagged %&gt;%\n  mutate(\n    fit_link  = pred_lagged$fit,\n    se_link   = pred_lagged$se.fit,\n    fit_resp  = plogis(fit_link),\n    lower_resp = plogis(fit_link - 2 * se_link),\n    upper_resp = plogis(fit_link + 2 * se_link)\n  )\n\np_lagged &lt;- ggplot(newdata_lagged, aes(x = causalness_lagged)) +\n  geom_line(aes(y = fit_resp), color = \"#fc8961\", linewidth = 1.2) +\n  geom_ribbon(aes(ymin = lower_resp, ymax = upper_resp), fill = \"#fc8961\", alpha = 0.2) +\n  labs(x = \"Causalness Lagged\", y = \"Proportion of Anticausative\") +\n  ylim(0, 1) +\n  theme_minimal()\n\n# ---- 2. Prediction grid for causalness_degree by language (interaction) ----\nnewdata_degree &lt;- expand.grid(\n  causalness_degree = seq(min(join$causalness_degree, na.rm = TRUE), max(join$causalness_degree, na.rm = TRUE), length.out = 200),\n  language = levels(join$language)\n) %&gt;%\n  as_tibble() %&gt;%\n  mutate(\n    causalness_lagged = mean(join$causalness_lagged, na.rm = TRUE),\n    language = factor(language, levels = levels(join$language))\n  )\n\npred_degree &lt;- predict(model, newdata_degree, type = \"link\", se.fit = TRUE)\n\nnewdata_degree &lt;- newdata_degree %&gt;%\n  mutate(\n    fit_link   = pred_degree$fit,\n    se_link    = pred_degree$se.fit,\n    fit_resp   = plogis(fit_link),\n    lower_resp = plogis(fit_link - 2 * se_link),\n    upper_resp = plogis(fit_link + 2 * se_link)\n  )\n\np_degree_int &lt;- ggplot(newdata_degree, aes(x = causalness_degree, y = fit_resp, linetype = language)) +\n  geom_line(color = \"#fc8961\", linewidth = 1.2) +\n  geom_ribbon(aes(ymin = lower_resp, ymax = upper_resp), fill = \"#fc8961\", alpha = 0.2, color = NA) +\n  labs(x = \"Causalness Degree\", y = \"Proportion of Anticausative\", linetype = \"Language\") +\n  ylim(0, 1) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n# ---- 4. Prediction grid for causalness_lagged by language (interaction) ----\nnewdata_lagged_int &lt;- expand.grid(\n  causalness_lagged = seq(min(join$causalness_lagged), max(join$causalness_lagged), length.out = 200),\n  language = levels(join$language)\n) %&gt;%\n  as_tibble() %&gt;%\n  mutate(\n    causalness_degree = mean(join$causalness_degree, na.rm = TRUE),\n    language = factor(language, levels = levels(join$language))\n  )\n\npred_lagged_int &lt;- predict(model, newdata_lagged_int, type = \"link\", se.fit = TRUE)\n\nnewdata_lagged_int &lt;- newdata_lagged_int %&gt;%\n  mutate(\n    fit_link   = pred_lagged_int$fit,\n    se_link    = pred_lagged_int$se.fit,\n    fit_resp   = plogis(fit_link),\n    lower_resp = plogis(fit_link - 2 * se_link),\n    upper_resp = plogis(fit_link + 2 * se_link)\n  )\n\np_lagged_int &lt;- ggplot(newdata_lagged_int, aes(x = causalness_lagged, y = fit_resp, linetype = language)) +\n  geom_line(color = \"#fc8961\", linewidth = 1.2) +\n  geom_ribbon(aes(ymin = lower_resp, ymax = upper_resp), fill = \"#fc8961\", alpha = 0.2, color = NA) +\n  labs(\n    x = \"Causalness Lagged\",\n    y = \"Proportion of Anticausative\",\n    linetype = \"Language\"\n  ) +\n  ylim(0, 1) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\np_lagged\n\n\n\n\n\n\n\np_lagged_int\n\n\n\n\n\n\n\np_degree_int"
  },
  {
    "objectID": "LICENSE-data.html",
    "href": "LICENSE-data.html",
    "title": "",
    "section": "",
    "text": "Creative Commons Attribution 4.0 International (CC BY 4.0)\nThis work is licensed under the Creative Commons Attribution 4.0 International License.\nYou are free to:\n\nShare — copy and redistribute the material in any medium or format\nAdapt — remix, transform, and build upon the material for any purpose, even commercially\n\nUnder the following terms:\n\nAttribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made.\n\nNo additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.\nFull license text: https://creativecommons.org/licenses/by/4.0/"
  }
]